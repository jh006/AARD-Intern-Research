# -*- coding: utf-8 -*-
"""Triple dip_JULIA SUMMERCAMP PYTHON CODE

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-DtrbS96k8-IGW7bjvSMoHj0mJWChsH5
"""

import torch  # to use PyTorch (optimized tensor library for deep learning using GPU and CPU)
from torch import nn  #module torch. nn: diff classes, help  build nns
from torch.utils.data import DataLoader, Dataset
import numpy as np   # NumPy: Python library used for working w/arrays
                     #np.arrange, np.random.shuffle
import pandas as pd  #pandas: software library for data manipulation + analysis
                     #pd.read.csv   
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
#from torchmetrics import R2Score
import matplotlib.pyplot as plt
import torch.optim as optim
import math
from sklearn.model_selection import train_test_split
from scipy.linalg import norm

torch.cuda.is_available()
from google.colab import drive   #importing drive
drive.mount('/content/drive')

pip install -U --no-cache-dir gdown --pre

#download the data from google drive to colab and read them
! gdown --id 1WJVQOxcO1b4jAPlAnh1lW_X_6umiJxI4
df1 = pd.read_csv("parameters.csv",header=None)
print(df1.head()) #gives first 5 rows
print(df1.shape) #prints number of rows

! gdown --id 13N_-Eqw1JjhwP8uuEmx_fWqbNYzosoJ5
df2 = pd.read_csv("real_t.csv",header=None)
print(df2.head()) #gives first 5 rows
print(df2.shape) #prints number of rows
 
! gdown --id 1LVX7n6qRWETKNr5FLxd015fYk86MTMDA
df3 = pd.read_csv("imag_t.csv",header=None)
print(df3.head()) #gives first 5 rows
print(df3.shape) #prints number of rows
 
x_full=torch.tensor(df1.iloc[0:len(df1)].values).float().cuda()   #full x data from parameters.csv
real_full=torch.tensor(df2.iloc[0:len(df2)].values).float().cuda()   #full y data from real_t
imag_full=torch.tensor(df3.iloc[0:len(df3)].values).float().cuda()   #full y data from imag_t
#check the range of the four parameters
permittivity_min=12
permittivity_max=25
print(min(x_full[:,0]))
print(max(x_full[:,0]))
gap_min=0.1
gap_max=1.55
print(min(x_full[:,1]))
print(max(x_full[:,1]))
thickness_min=0.5
thickness_max=1.55
print(min(x_full[:,2]))
print(max(x_full[:,2]))
index_min=0.1
index_max=1.05
print(min(x_full[:,3]))
print(max(x_full[:,3]))

#use the 4 parameters in figure 6 para=torch.tensor([21.98,1.48,1.45,0.68]).float().cuda()  #page 3203 dual band target   
# use the PNN(para) as the input of DNN model to check if the predicted DNN output is close to para
 
#define PNN model and load the trained PNN model
# the f function in the papter(calculate tensor product using einsum)
def f(x, W1,W2, V, b): #def bilinear function; x is a N*1*4
  n=len(x)
  xsq = torch.transpose(torch.mul(x, x),1,0)  #squares x
  xt=torch.transpose(x, 1,0)
  xT_W1 =torch.einsum("mj,ijk",x,W1).permute(0,2,1).cuda()
  xT_W1_x=torch.transpose(torch.diagonal(torch.einsum("ijk,km", xT_W1,xt), offset=0, dim1=1, dim2=2),1,0) #n*50
  xT_W2 =torch.einsum("mj,ijk",x,W2).permute(0,2,1).cuda()
  xT_W2_x=torch.transpose(torch.diagonal(torch.einsum("ijk,km", xT_W2,xsq), offset=0, dim1=1, dim2=2),1,0) #n*50
  V_xcat= torch.transpose(torch.mm(V,torch.cat((xt, xsq))),1,0)
  b1=torch.transpose(b.repeat(1,n),1,0)
  Q= xT_W1_x+xT_W2_x+V_xcat+b1
  return(Q)  

#define the PNN model

class NeuralNetwork(nn.Module):   #https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.flatten = nn.Flatten()
        self.params = nn.ParameterDict({
                'W1': nn.Parameter(torch.ones(50, 4, 4).cuda(), requires_grad = True),
                'W2': nn.Parameter(torch.ones(50, 4, 4).cuda(), requires_grad = True),
                'V':  nn.Parameter(torch.ones(50,8).cuda(), requires_grad = True),
                'b':  nn.Parameter(torch.ones(50,1).cuda(), requires_grad = True)

        })   
        self.linear_relu_stack = nn.Sequential(   #nn.Sequential -> output of each layer as input of next layer
            nn.ReLU(),  #ReLU: activation function (defines output/what goes into next layer)
            nn.Linear(50, 500), # creates single layer feed forward network with 50 inputs and 500 outputs
            nn.ReLU(),
            nn.Linear(500, 500),
            nn.ReLU(),
            nn.Linear(500, 500),
            nn.ReLU(),
            nn.Linear(500, 301),
        )
    
    def forward(self, x): #def forward function
       Q=f(x, self.params['W1'],self.params['W2'],self.params['V'], self.params['b'])
       logits = self.linear_relu_stack(Q)
       return logits

PNN_real = NeuralNetwork().cuda()    #define real PNN model
PNN_imag = NeuralNetwork().cuda()    #define image PNN model

#define save function to save checkpoint 
# after each iteration, the trained model, and results are saved, and will be loaded in the next iteration 
import shutil
def save_ckp(state, checkpoint_path):
    f_path = checkpoint_path
    torch.save(state, f_path)
    
def load_ckp(checkpoint_fpath, model, optimizer):
    checkpoint = torch.load(checkpoint_fpath)
    model.load_state_dict(checkpoint['state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
  #  valid_loss_min = checkpoint['valid_loss_min']
    return model, optimizer, checkpoint['epoch'], checkpoint['Rsquare'],  checkpoint['TRAIN_LOSS'], checkpoint['TEST_LOSS'],checkpoint['inx']

 
#page 3203 dual band targe 
para=torch.tensor([21.45,1.43,1.26,1]).float().cuda()    
para=torch.reshape(para, (1,4))
 
PNN_real = NeuralNetwork().cuda() 
optimizer = optim.Adam(PNN_real.parameters(), lr = 1e-05)
current_checkpoint_PNN_real="/content/drive/MyDrive/current_checkpoint_PNN_real.pth" 
PNN_real, optimizer, start_epoch, r_squared_real,Trainloss_real,Testloss_real,indices_real = load_ckp(current_checkpoint_PNN_real, PNN_real, optimizer)
PNN_real.eval() #not optimize, for each epoch: test loss
pred_para_real=PNN_real(para)
pred_para_real_np=pred_para_real.cpu().detach().numpy()

PNN_imag = NeuralNetwork().cuda() 
optimizer = optim.Adam(PNN_imag.parameters(), lr = 1e-05)
current_checkpoint_PNN_imag="/content/drive/MyDrive/current_checkpoint_PNN_imag.pth" 
PNN_imag, optimizer, start_epoch, r_squared_imag,Trainloss_imag,Testloss_imag,indices_imag = load_ckp(current_checkpoint_PNN_imag, PNN_imag, optimizer)
pred_para_imag=PNN_imag(para)
pred_para_imag_np=pred_para_imag.cpu().detach().numpy()
amplitude_para_np=np.sqrt(np.square(pred_para_real_np)+np.square(pred_para_imag_np))
dual_full=torch.tensor(amplitude_para_np).cuda() #calculated target spectrum from the parameters on page 3202


frequency=np.arange(30, 60.1, 0.1) 
plt.plot(frequency,amplitude_para_np[0,], '-o')# the ith row of the predicted real data
plt.xlabel('Frequency')
plt.title('Calculated target spectrum from parameters='+str(para)+  "\n From figure 6")
plt.ylabel('Calculated target spectrum')
plt.show()

#define the DNN model --Table S1
low=torch.tensor([12,0.1,0.5,0.1]).cuda()
up=torch.tensor([25,1.55,1.55,1.05]).cuda()
class matafilter(nn.Module):   #https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html
    def __init__(self):
        super(matafilter, self).__init__()
        self.layers = nn.Sequential(
            nn.Linear(301, 500),      # creates single layer feed forward network with 301 inputs and 500 outputs
            nn.Sigmoid(),
            nn.Linear(500, 500),
            nn.Sigmoid(),
            nn.Linear(500, 500),
            nn.Sigmoid(),
            nn.Linear(500, 50),
            nn.Sigmoid(),
            nn.Linear(50, 4),
         )

    def forward(self, x):
        DNNoutput = self.layers(x)
       # Q=PNN(logits)
        #pred_real=PNN_real(DNNoutput) #apply trainded PNN real data model to get the real part of designed spectra
        #pred_imag=PNN_imag(DNNoutput) #apply trainded PNN image data model to get the real part of designed spectra 
        #result = torch.sqrt(torch.mul(pred_real, pred_real) +torch.mul(pred_imag, pred_imag)) # amplitude of designed spetra
        return DNNoutput
DNN = matafilter().cuda()    #define model
print(DNN)

from os import minor
#define save function to save checkpoint of trained DNN model
# after each iteration, the trained model, and results are saved, and will be loaded in the next iteration 
import shutil
def save_ckp_DNN(state, checkpoint_path):
    f_path = checkpoint_path
    torch.save(state, f_path)
    
def load_ckp_DNN(checkpoint_fpath, model, optimizer):
     checkpoint = torch.load(checkpoint_fpath)
     model.load_state_dict(checkpoint['state_dict'])
     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
   #  valid_loss_min = checkpoint['valid_loss_min']
     return model, optimizer, checkpoint['epoch'], checkpoint['Rsquare'], checkpoint['loss_s'], checkpoint['TRAIN_LOSS'], checkpoint['LOSS1'],checkpoint['LOSS2'],checkpoint['inx']

#define the function to train the model using simulated dual band data
def DNN_train(start_epoch, num_epoch, DNN, optimizer, checkpoint_path, best_path):
    
    print("learning rate", lr)  
    if start_epoch==1: smallest_loss=100
    else: smallest_loss=min(Trainloss)
    low=torch.tensor([12,0.1,0.9,0.1]).cuda() # the lower limits of the four parameters
    up=torch.tensor([25,1.55,1.55,1.05]).cuda() #the upper limits of the four parameters
    loss_func=nn.MSELoss()
    DNN.train()
    for epoch in range(start_epoch, num_epoch+start_epoch):
        optimizer.zero_grad()    
        x_train =Variable(dual_full)   #simulated dual band target spectra
        DNNoutput=DNN(x_train)
        DNNoutput_clipped=torch.clamp(DNNoutput, min=low, max=up)
        pred_real=PNN_real(DNNoutput_clipped) #apply trainded PNN real data model to get the real part of designed spectra
        pred_imag=PNN_imag(DNNoutput_clipped) #apply trainded PNN image data model to get the real part of designed spectra 
        dual_pred= torch.sqrt(torch.mul(pred_real, pred_real) +torch.mul(pred_imag, pred_imag)) # amplitude of designed spetra
        loss1=loss_func(dual_full,dual_pred)
        loss2= DNNoutput.size(dim=1)*loss_func(DNNoutput, DNNoutput_clipped)  #DNNoutput.size(dim=1) is the length of the DNNoutput. It is 4 in this code
        loss = loss1+loss2
        Trainloss.append(loss.item())  # record the loss
        LOSS1.append(loss1.item())  # record the loss
        LOSS2.append(loss2.item())  # record the loss
        indices.append(epoch+1)    #record epoch

        #calculate the correlation  
        dual_pred_np=dual_pred.detach().cpu().numpy().flatten()
        dual_full_np=dual_full.detach().cpu().numpy().flatten()
        r2=r2_score(dual_pred_np, dual_full_np) 
        r_squared.append(r2)

        checkpoint = {
            'epoch': epoch + 1,
            'Rsquare': r_squared,
            'loss_s': loss_s,
            'TRAIN_LOSS': Trainloss,
            'LOSS1': LOSS1,
            'LOSS2': LOSS2,           
            'inx':indices,
            #'valid_loss_min': valid_loss,
            'state_dict': DNN.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
        }  

        if epoch%1000==1 or epoch==num_epoch+start_epoch-1 or loss<smallest_loss: 
        #if epoch%1000==1 or epoch==num_epoch+start_epoch-1 : 
           print('epoch', epoch)
           print('smallest loss',smallest_loss)
           print("TRAIN_LOSS", Trainloss[-5:])
           print("loss1",loss1)
           print("loss2",loss2)
           print("DNNoutput", DNNoutput)
           print("DNNoutput_clipped", DNNoutput_clipped)
           #print("21.98,1.48,1.45,0.68")
           #print("Rsquare",r_squared[-5:])
           save_ckp_DNN(checkpoint, checkpoint_path)
        if loss<smallest_loss: 
           print("new model saved")
           save_ckp_DNN(checkpoint, best_path)
           smallest_loss=loss 
           print("current smallest loss",smallest_loss) 

        loss_s.append(smallest_loss)
        DNN.zero_grad()
        loss.backward(retain_graph=True)
        optimizer.step()
    
    return DNN

torch.manual_seed(0)
lr =1e-1

start_epoch=1
if (start_epoch==1):
    Maximum_Rsquare=0
    Trainloss=[] # loss of every epoch in iteration for training data
    LOSS1=[] # loss of every epoch in iteration for training data
    LOSS2=[] # loss of every epoch in iteration for training data
    loss_s=[]
    r_squared = []
    indices = []  #epochs
    y_pred = []
    
    from torch.autograd import Variable  # Variable wraps tensor, gives way to perform backpropagation
    DNN = matafilter().cuda()    #define model
    optimizer = optim.Adam(DNN.parameters(), lr = lr)
    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)
    loss_func=nn.MSELoss()
    start_epoch=1 
    num_epoch=1
    current_checkpoint="/content/drive/MyDrive/current_checkpoint_DNN_tripledip.pth" 
    best_checkpoint="/content/drive/MyDrive/best_checkpoint_DNN_tripledip.pth" 

    trained_DNN = DNN_train(start_epoch, num_epoch, DNN, optimizer, current_checkpoint,best_checkpoint) #train the model and save the checkpoint
 
else:

    print('start epoch:',start_epoch) 
    #print(model)
    #print(optimizer)
    #print(start_epoch) 
    print(Trainloss[-5:])
    print(indices[-5:])
    print(r_squared[-5:])
    num_epoch=1
    trained_DNN = DNN_train(start_epoch, num_epoch, DNN, optimizer, current_checkpoint,best_checkpoint) #train the model and save the checkpoint

from torch.autograd import Variable  # Variable wraps tensor, gives way to perform backpropagation
lr =1e-01
loss_func=nn.MSELoss()
DNN = matafilter().cuda()    #define model
optimizer = optim.Adam(DNN.parameters(), lr = lr)
#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)
current_checkpoint="/content/drive/MyDrive/current_checkpoint_DNN_tripledip.pth" 
best_checkpoint="/content/drive/MyDrive/best_checkpoint_DNN_tripledip.pth" 

DNN, optimizer, start_epoch, r_squared, loss_s, Trainloss,LOSS1,LOSS2,indices = load_ckp_DNN(current_checkpoint, DNN, optimizer)
 
num_epoch=10000 # number of iterations
import time
start = time.time()
#print("design parameter",para)
DNN = DNN_train(start_epoch, num_epoch, DNN, optimizer, current_checkpoint,best_checkpoint) #train the model and save the checkpoint
end = time.time()
print("running time", end - start)

#Apply the best trained model to the dual band data
#current_checkpoint="/content/drive/MyDrive/current_checkpoint_DNN_dualband0817.pth" 
best_checkpoint="/content/drive/MyDrive/best_checkpoint_DNN_tripledip.pth" 
loss_func=nn.MSELoss()
DNN = matafilter().cuda()    #define model
optimizer = optim.Adam(DNN.parameters(), lr=1e-01)
DNN, optimizer, start_epoch, r_squared, loss_s, Trainloss,LOSS1,LOSS2,indices = load_ckp_DNN(best_checkpoint, DNN, optimizer)
DNN.eval() #not optimize, for each epoch: test loss
with torch.no_grad(): # stop updating the parameters
   DNN_pred = DNN(dual_full)
   pred_real=PNN_real(DNN_pred)
   pred_imag=PNN_imag(DNN_pred)
   dual_pred = torch.sqrt(torch.mul(pred_real, pred_real) +torch.mul(pred_imag, pred_imag)) 
 
low=torch.tensor([12,0.1,0.5,0.1]).cuda()
up=torch.tensor([25,1.55,1.55,1.05]).cuda() 
DNN_pred_clipped=torch.clamp(DNN_pred, min=low, max=up)
loss_1=loss_func(dual_pred,dual_full.cuda())
loss_2=4*loss_func(DNN_pred, DNN_pred_clipped)
loss_DNN=loss_1+loss_2 
print("loss1", loss_1)
print("loss2", loss_2)
print("LOSS_DNN", loss_DNN)
 

#calculate the r-square for the full real data
dual_pred2=dual_pred.detach()
dual_full2=dual_full.detach()
print("designed parameters:", para)
print("predicted parameters:",DNN_pred)

 
dual_pred_np=dual_pred.cpu().numpy()
dual_full_np=dual_full.cpu().numpy()
r2=np.corrcoef(dual_pred_np, dual_full_np)[0,1]
print('r2_corrcoef:', r2)
dual_pred_np=dual_pred.detach().cpu().numpy().flatten()
dual_full_np=dual_full.detach().cpu().numpy().flatten()
r2=r2_score(dual_pred_np, dual_full_np) 
print('r2_score:', r2)         
 
#save the first 100 plots into one pdf file
from matplotlib.backends.backend_pdf import PdfPages
from google.colab import files
#plot Real vs predicted for selected row of test data

dual_pred_np=dual_pred.cpu().numpy()
dual_full_np=dual_full.cpu().numpy()
y = dual_full_np  
y_p=dual_pred_np  
frequency=np.arange(30, 60.1, 0.1) 
size=15
pdf = PdfPages('Target spectra vs designed spectra.pdf')
for i in range(1): 
        fig, ax = plt.subplots(figsize=(10, 10))
        plt.plot(frequency,y[i,], '-o')  # the ith row of all real data
        plt.plot(frequency,y_p[i,], '-o')# the ith row of the predicted real data
        plt.xlabel('Frequency',fontsize = size)
        plt.ylabel('SPectra',fontsize = size)
        plt.legend(['target spectra','designed spectra'],fontsize = size)
        #plt.title('target spectra vs designed spectra  \n'+'single band_2, lr='+str(lr)+', num_epoch='+str(num_epoch) )

        pdf.savefig(fig)
        plt.show()

files.download("Target spectra vs designed spectra.pdf") 
pdf.close()

#plot the model loss
from matplotlib.backends.backend_pdf import PdfPages
from google.colab import files
pdf = PdfPages('DNN Model Loss.pdf')
fig, ax = plt.subplots(figsize=(10, 10))

plt.yscale('log') #change the y-axis  scale to logarithmic
k=num_epoch # plot Model loss until kth iteration

plt.plot(Trainloss[0:k])
 
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(['Train Loss'])
plt.title('DNN Model Loss \n'+'lr='+str(lr)+', num_epoch='+str(num_epoch) )
 
#plt.savefig("Model Loss_Epoch="+str(k)+ ".png")
pdf.savefig(fig)
plt.show()

#files.download("DNN Model Loss.pdf") 
pdf.close()

#plot the model loss
from matplotlib.backends.backend_pdf import PdfPages
from google.colab import files
pdf = PdfPages('DNN Model Loss1.pdf')
fig, ax = plt.subplots(figsize=(10, 10))

plt.yscale('log') #change the y-axis  scale to logarithmic

plt.plot(LOSS1[0:k])
 
plt.xlabel('Epoch')
plt.ylabel('LOSS1')
plt.legend(['LOSS1'])
plt.title('DNN Model Loss1 \n'+'lr='+str(lr)+', num_epoch='+str(num_epoch) )
 
#plt.savefig("Model Loss_Epoch="+str(k)+ ".png")
pdf.savefig(fig)
plt.show()

#files.download("DNN Model Loss.pdf") 
pdf.close()

#plot the model loss
from matplotlib.backends.backend_pdf import PdfPages
from google.colab import files
pdf = PdfPages('DNN Model Loss2.pdf')
fig, ax = plt.subplots(figsize=(10, 10))

plt.yscale('log') #change the y-axis  scale to logarithmic

plt.plot(LOSS2[0:k])
 
plt.xlabel('Epoch')
plt.ylabel('LOSS2')
plt.legend(['LOSS2'])
plt.title('DNN Model Loss2 \n'+'lr='+str(lr)+', num_epoch='+str(num_epoch))
#plt.savefig("Model Loss_Epoch="+str(k)+ ".png")
pdf.savefig(fig)
plt.show()

#files.download("DNN Model Loss.pdf") 
pdf.close()

#plot the model loss
from matplotlib.backends.backend_pdf import PdfPages
from google.colab import files
pdf = PdfPages('DNN Model R-square.pdf')
fig, ax = plt.subplots(figsize=(10, 10))

 
plt.plot(r_squared[1000:k])
 
plt.xlabel('Epoch')
plt.ylabel('R-square')
plt.title('DNN Model R-square \n'+'lr='+str(lr)+', num_epoch='+str(num_epoch) )
#plt.savefig("Model Loss_Epoch="+str(k)+ ".png")
pdf.savefig(fig)
plt.show()

#files.download("DNN Model R-square.pdf") 
pdf.close()

#save the first 100 plots into one pdf file
from matplotlib.backends.backend_pdf import PdfPages
from google.colab import files
#plot Real vs predicted for selected row of test data
#k=65611 #the kth row of the real data
dual_pred_np=dual_pred.cpu().numpy()
dual_full_np=dual_full.cpu().numpy()
y = dual_full_np  
y_p=dual_pred_np  
frequency=np.arange(30, 60.1, 0.1) 
pdf = PdfPages('Target spectra vs designed spectra.pdf')
for i in range(1): 
        fig, ax = plt.subplots(figsize=(10, 10))
        plt.plot(frequency,y[i,], '-o')  # the ith row of all real data
        plt.plot(frequency,y_p[i,], '-o')# the ith row of the predicted real data
        plt.xlabel('Frequency')
        plt.ylabel('y')
        plt.legend(['target spectra','designed spectra'])
        plt.title('target spectra vs designed spectra  \n'+'lr='+str(lr)+', num_epoch='+str(num_epoch))
        pdf.savefig(fig)
        plt.show()

files.download("Target spectra vs designed spectra.pdf") 

pdf.close()